# NexGenTeck AI Chatbot Backend

A **fully softcoded** AI chatbot that uses LLM for intent interpretation and RoBERTa for sentiment analysis. No hardcoded regex patterns - the AI understands prompts dynamically.

## Features

- ğŸ§  **Hybrid Intelligence**: RoBERTa for sentiment + LLM for intent
- ğŸ” **RAG Pipeline**: LangGraph orchestrates analyze â†’ retrieve â†’ generate
- ğŸŒ **Multilingual**: BAAI/bge-m3 embeddings support multiple languages
- ï¿½ **Website Knowledge**: Auto-scrapes entire website for context
- ï¿½ **GCP Ready**: Dockerfile for Cloud Run deployment

## Architecture

```
User Message
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RoBERTa Sentiment Analysis       â”‚  â† Word-level understanding
â”‚  (cardiffnlp/twitter-roberta)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Intent Detection             â”‚  â† Softcoded, no regex
â”‚  (Llama 3.3 70B via Groq)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qdrant Vector Search             â”‚  â† Website knowledge
â”‚  (BAAI/bge-m3 embeddings)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Response Generation          â”‚  â† Context-aware response
â”‚  (Llama 3.3 70B via Groq)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Response
```

## Models Used

| Component | Model | Purpose |
|-----------|-------|---------|
| Embeddings | `BAAI/bge-m3` | Multilingual text embeddings (1024 dim) |
| Sentiment | `cardiffnlp/twitter-roberta-base-sentiment-latest` | Word-level sentiment analysis |
| LLM | `llama-3.3-70b-versatile` | Intent detection & response generation |

## Quick Start

### 1. Set Up Environment

```bash
cd Chatbot
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Locally

```bash
uvicorn main:app --reload --port 8000
```

### Production (Docker Compose, DigitalOcean-friendly)

1) Copy `.env.example` to `.env` and set real values:
  - `GROQ_API_KEY` (required)
  - `WEBSITE_URL` to your live site (do **not** leave localhost in prod)
  - `QDRANT_URL=http://qdrant:6333` (matches the compose service)
2) Build and run with Qdrant:
```bash
docker compose up -d --build
```
3) Check health and document count:
```bash
curl -fsS http://127.0.0.1:8000/health
```
4) To force re-ingestion after website changes:
```bash
curl -X POST http://127.0.0.1:8000/reindex
```

### 4. Test the API

```bash
# Health check
curl http://localhost:8000/health

# Send a message
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!"}'

# Ask a question
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What services does NexGenTeck offer?"}'
```

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Basic info and status |
| `/health` | GET | Health check for monitoring |
| `/chat` | POST | Send a message and get response |
| `/reindex` | POST | Re-scrape website and update knowledge |

## GCP Deployment

### Cloud Run

```bash
# Build and push to Container Registry
gcloud builds submit --tag gcr.io/YOUR_PROJECT/chatbot ./Chatbot

# Deploy to Cloud Run
gcloud run deploy chatbot \
  --image gcr.io/YOUR_PROJECT/chatbot \
  --platform managed \
  --region us-central1 \
  --set-env-vars GROQ_API_KEY=your_key \
  --allow-unauthenticated \
  --memory 4Gi \
  --cpu 2
```

## Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GROQ_API_KEY` | âœ… | - | Your Groq API key |
| `WEBSITE_URL` | âŒ | https://nexgenteck.com | URL to scrape |
| `EMBEDDING_MODEL` | âŒ | BAAI/bge-m3 | Embedding model |
| `LLM_MODEL` | âŒ | llama-3.3-70b-versatile | Groq model name |
| `LLM_TEMPERATURE` | âŒ | 0.7 | Response creativity |
| `MAX_CONTEXT_DOCS` | âŒ | 5 | Docs to retrieve |

## Project Structure

```
Chatbot/
â”œâ”€â”€ main.py           # FastAPI application
â”œâ”€â”€ config.py         # Environment configuration
â”œâ”€â”€ sentiment.py      # RoBERTa + LLM hybrid analyzer
â”œâ”€â”€ rag_pipeline.py   # LangGraph RAG workflow
â”œâ”€â”€ scraper.py        # Comprehensive website scraper
â”œâ”€â”€ embeddings.py     # BAAI/bge-m3 embedding manager
â”œâ”€â”€ vector_store.py   # Qdrant operations
â”œâ”€â”€ utils.py          # Text utilities
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ Dockerfile        # GCP container config
â””â”€â”€ .env.example      # Environment template
```

## How It Works (Softcoded)

1. **No Hardcoded Patterns**: Intent is detected by LLM, not regex
2. **RoBERTa Sentiment**: Uses word dictionary for accurate sentiment
3. **LLM Intent**: Understands "What services do you offer?" without patterns
4. **Website Context**: All responses based on scraped website content

## License

Proprietary - NexGenTeck Â© 2026
