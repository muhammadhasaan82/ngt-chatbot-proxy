# NexGenTeck AI Chatbot Environment Variables
# Copy this to .env and fill in your values

# Required: Groq API Key for Llama 3.3
GROQ_API_KEY=your_groq_api_key_here

# Website to scrape for knowledge base
WEBSITE_URL=https://nexgenteck.github.io/

# CORS origins (comma-separated for multiple)
CORS_ORIGINS=https://nexgenteck.github.io,https://muhammadhasaan82.github.io,http://165.245.177.103

# Model Configuration
# BAAI/bge-m3: Multilingual embeddings (1024 dimensions)
EMBEDDING_MODEL=BAAI/bge-m3
# Llama 3.3 70B for LLM generation
LLM_MODEL=llama-3.3-70b-versatile
# RoBERTa is used for sentiment analysis (hardcoded in sentiment.py)

# RAG Configuration
MAX_CONTEXT_DOCS=5
RELEVANCE_THRESHOLD=1.5

# LLM Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

# Qdrant Configuration
# In production, point to your Qdrant service (e.g., docker-compose service name)
QDRANT_URL=http://qdrant:6333
COLLECTION_NAME=nexgenteck_knowledge
